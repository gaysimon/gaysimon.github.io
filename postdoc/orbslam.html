<!DOCTYPE html>
<html >
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="/style1.css" type="text/css" />
	<title>Simon GAY</title>
</head>

<body>
	
	<header>
		<div id="banniere_image"> </div>
	</header>
	
	<div class="main">
		<nav>
                	<a href="/index.html">Accueil</a><br />
			<a href="/recherches.html">Recherches</a><br />
			<a href="/postdoc.html">Mon PostDoc</a><br />
			<a href="/these.html">Ma These</a><br />
			<a href="/publi.html">Publications</a><br />
			<a href="/robot.html">Les Robots</a><br />
			<a href="/software.html">logiciels</a><br />
			<br />
			<a href="/postdoc/orbslam.html"><img src="/img/fr.png" alt="fr" /> </a>
			<a href="/postdoc/orbslam_en.html"><img src="/img/en.png" alt="en" /> </a>
		</nav>

		<section class="subsection">
			<p>
				<center style="text-align: center;font-size: xx-large;">Tests du système ORB-SLAM</center><br /><br />
			</p>

			<p>
				Dans un premier temps, nous avons envisagé d'utiliser le système <a href="https://github.com/raulmur/ORB_SLAM">ORB-SLAM<a/> dans nos modèles de navigation. ORB-SLAM est un système de cartographie et de localisation monoculaire ou stéréo basé sur le détecteur de caractéristique <a href="https://en.wikipedia.org/wiki/Oriented_FAST_and_rotated_BRIEF">ORB<a/> particulièrement efficace.  
			</p>

			<p>
				Il était ainsi prévu d'utiliser ce modèle pour reconnaître les lieux déjà visités pour se localiser et s'orienter de façon précise à l'aide d'une caméra dotée d'une lentille fisheye. L'interface développée par notre <a href="https://fr.linkedin.com/in/pierre-biojoux-1b418815a">stagiaire<a/> permettait de tester et échanger rapidement les modèles de l'environnement pour permettre la construction d'un graphe de navigation.
			</p>

			<figure style="text-align:center">
				<img src="/postdoc/OrbSlam.png" alt="Système ORB-SLAM" width="400" />
			</figure>

			<p style="text-align: center">
				Le système ORB-SLAM détecte des points d'intérêt et utilise les mouvements de la caméra pour localiser ces points dans l'espace et construire un modèle de l'environnement (à droite) permettant de se localiser.
			</p>

			<p>
				Cependant, le système souffre de certaines limites : dans sa version mono-caméra, le système ne peut pas gérer des mouvements de rotation sans translation de la caméra, et est peu tolérant aux environnements dynamiques. De plus, les modèles créés sont particulièrement volumineux (près d'une centaine de Mo pour un simple bureau), le rendant peu adapté aux grands environnements. Ces problèmes nous ont poussé à envisager des solutions plus simples à base de systèmes de vision stéréo. 
			</p>

		</section>
	</div>
	
	<footer>
		<p>
			Derniers ajouts par section
		</p>

		<div class="footsection">
			<p>
				&nbsp;ROBOTS :<br />
				&nbsp;&nbsp;<a href="index.php?page=john1">Johnny </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=john2">Johnny 2.0 </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=eirl">ErnestIRL </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=psik">PsikHarpax </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=ecce">EcceRobot </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=epuck">ePuck </a> <br />
			</p>
		</div>

		<div class="footsection">
			<p>
				&nbsp;SOFTWARES :<br />
				&nbsp;&nbsp;<a href="index.html">SMA </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=vacu">vacuumSG </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=littleai">Java LittleAI </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=mvac">Microvacuum </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=esimu">ErnestIRL simulator </a> <br />
			</p>


		</div>

		<div class="footsection">
			<p>
				&nbsp;Le projet Ernest
			</p>
		</div>
	</footer>

</body>
</html>
