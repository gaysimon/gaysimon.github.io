<!DOCTYPE html>
<html >
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="/style1.css" type="text/css" />
	<title>Simon GAY</title>
</head>

<body>
	
	
	<header>
		<div id="banniere_image"> </div>
	</header>
	
	<div class="main">
		<nav>
                	<a href="/index.html">Accueil</a><br />
			<a href="/recherches.html">Recherches</a><br />
			<a href="/postdoc.html">Mon PostDoc</a><br />
			<a href="/these.html">Ma These</a><br />
			<a href="/publi.html">Publications</a><br />
			<a href="/robot.html">Les Robots</a><br />
			<a href="/software.html">logiciels</a><br />
			<br />
			<a href="/robot/robot_navigation.html"><img src="/img/fr.png" alt="fr" /> </a>
			<a href="/robot/robot_navigation_en.html"><img src="/img/en.png" alt="en" /> </a>
		</nav>

		<section class="subsection">
			<p>
				<center style="text-align: center;font-size: xx-large;">Plateforme robotique omni-directionnelle</center><br /><br />
			</p>
			

			<figure style="text-align:center">
				<img src="/projects/robot.jpg" alt="robotic platform" width="600" />
			</figure>
			<p style="text-align: center">
				Une plateforme omni-directionnelle pour étudier des modèles de navigation autonome.
			</p>

			<p>
				<br/>
				<br/>
				
				Ce robot a été conçu pour tester et valider nos <a href="https://gaysimon.github.io/postdoc/navig2.html">modèles de navigation bio-inspirés</a> en environnement réel. Le choix de la plateforme a été dictée par différentes contraintes : déplacements omni-directionnels pour simuler les déplacements d'une personne, abordable pour pouvoir s'équiper d'une flottille de robot, et d'une taille suffisante pour pouvoir être équipé d'un nano-ordinateur et d'une caméra binoculaire. Notre choix s'est porté sur la plateforme Mecanuum Wheel produit par Osoyoo. Cette plateforme a ensuite été équipée d'un étage supplémentaire pour accueillir de nouveaux composants.



			
		</section>

		<section class="subsection">

			<p>
				<center style="text-align: center;font-size: xx-large;">La plateforme Mecanuum Wheel</center><br /><br />
			</p>

			<p>
				La plateforme Mecanuum Wheel de Osoyoo constitue une base intéressante pour notre plateforme de test : elle est relativement simple à assembler et propose des déplacements omni-directionnel. Son architecture, reposant sur des composants répandus (Arduino et carte de contrôle moteur L293), facilite l'interface avec des composants additionnels.
			</p>


			<figure style="text-align:center">
				<img src="/robot/mecanuum_platform.jpg" alt="mecanuum platform" width="400" />
			</figure>
			<p style="text-align: center">
				La plateforme Mecanuum Wheel assemblée. L'Arduino est équipé d'un shield Wifi/Bluetooth. Le kit comprend également un sonar monté sur un servomoteur ainsi qu'un capteur de ligne au sol. 
			</p>

			<p>
				La plateforme est équipée de quatre roues dite "mecanum", c'est à dire dotées de petites roulettes internes. Contrairement aux roues omni-directionnelles (ou roues holonomes), dont les roulettes sont perpendiculaires à l'axe de la roue, les roues mecanum ont des roulettes inclinées de 45° par rapport à l'axe. Cette configuration particulière permet, avec un robot équipé de quatre de ces roues, de pouvoir se déplacer dans toutes les directions, avec une direction particulière (avant/arrière) ne générant pas de frottement supplémentaire à cause du roulement des roulettes internes, contrairement aux robots holonomes à trois roues, dont les roulettes génèrent un frottement supplémentaire quelle que soit la direction.
			</p>


			<figure style="text-align:center">
				<img src="/robot/Mecanum_wheel_control_principle.png" alt="mecanuum wheels" width="600" />
			</figure>
			<p style="text-align: center">
				Déplacements d'un robot équipé de quatre roues mecanum. Lorsque deux roues du même côté tournent en sens inverse, le déplacement vers l'avant ou l'arrière s'annule, tandis que le roulement des roulettes provoque un déplacement sur le côté. En jouant sur la vitesse des quatre roues, le robot peut se déplacer dans toutes les directions (<a href="https://en.wikipedia.org/wiki/Mecanum_wheel">source</a>).
			</p>


			<p>	
				Démonstration des possibilités de déplacement de la plateforme, ici contrôlé avec une manette de jeux :
			</p>
			
			<p style="text-align: center">
 				<video width="400" controls >
  					<source src="/robot/robot_control.mp4" type="video/mp4">
					Your browser does not support the video tag.
				</video> 

			</p>

			<p>	
				Code source :<br>

				- Code Arduino : <a href="/robot/robot_control_bluetooth.ino">robot_control_bluetooth.ino</a> <br>

				- Interface Java : <br>
			</p>

<br />
		</section>

		<section class="subsection">

			<p>
				<center style="text-align: center;font-size: xx-large;">Une plateforme pour l'étude de modèles de navigation</center><br /><br />
			</p>

			<p>
				Afin de rendre le robot autonome, tout en permettant du traitement d'image et la localisation, la plateforme a été équipée d'un nano-ordinateur. Les célèbres Raspberry Pi 4 étant en rupture de stock en cette période, notre choix s'est porté sur un modèle équivalent : le <a href="https://wiki.banana-pi.org/Banana_Pi_BPI-M5">Banana Pi M5</a>. Celui-ci n'étant pas équipé d'une connexion Wifi, un dongle doit être ajouté. Le nano-ordinateur tourne sous Raspbian, un dérivé de Debian adapté pour les Raspberry Pi et cartes compatibles.
La caméra binoculaire est une caméra de Playstation 4 (PS4 eye) modifiée pour pouvoir être branchée sur un port USB3 (tutoriel disponible <a href="https://www.instructables.com/HACK-PlayStation-4-Cam-Into-Cheap-3D-Depth-Camera-/">ici</a>).
L'ensemble est alimenté par une batterie de type powerbank de 20Ah, indépendante de la batterie des moteurs. Le système communique avec la plateforme robotique par une connexion USB avec l'Arduino du robot.<br/>

			</p>
		
			<figure style="text-align:center">
				<img src="/robot/platform_components.jpg" alt="robot components" width="600" />
			</figure>
			<p style="text-align: center">
				Composants additionnels de la plateforme. De gauche à droite : l'ordinateur de bord Banana Pi M5 (équipé d'un dongle Wifi), La caméra binoculaire PS4 eye modifiée, et la batterie Powerbank.
			</p>
<br/>

			<p>
				Les composants additionnels sont placés sur une plaque de plexi de 5mm d'épaisseur maintenue au châssis par des entretoises, et tenu par des supports imprimés en 3D. Le boîtier du Banana Pi est basé sur <a href="https://www.thingiverse.com/thing:5147307">ce modèle</a>. Le support de la batterie est conçue pour une powerbank modèle Intenso XS20000. Ce support maintien également le dongle Wifi, relié au Banana Pi par une rallonge USB de 10cm. Les supports de la caméra sont conçus pour la version 1 de la PS4 eye. Il faut en imprimer deux, dont un qui doit être inversé (supports symétriques).<br />

			- Support batterie : <a href="/robot/batterie_support.stl">batterie_support.stl</a><br />
			- Support caméra : <a href="/robot/camera_support.stl">camera_support.stl</a><br />


			</p>

<br />
			<figure style="text-align:center">
				<img src="/robot/architecture_robot.svg" alt="robot components" width="500" />
			</figure>
			<p style="text-align: center">
				Architecture de la plateforme : à gauche, l'ordinateur de bord, équipé d'une caméra binoculaire et d'un dongle Wifi, et alimenté par une powerbank. Il communique par USB avec l'Arduino de la plateforme, qui pilote les moteurs via des cartes de contrôle. Les moteurs sont alimentés par leur propre batterie.
			</p>

<br />
	
			<p>
				La communication s'effectue par le port série USB. Voici le code source pour l'Arduino et une classe Java servant d'interface :<br />


				- code arduino : <a href="/robot/robot_control_usb.ino">robot_control_usb.ino</a> <br>

				- interface Java : <a href="/robot/Robot.java">Robot.java</a> (nécessite la librairie <a href="https://github.com/java-native/jssc/releases">JSSC</a>) <br>

<br />

			</p>
			
			
		</section>

		<section class="subsection">

			<p>
				<center style="text-align: center;font-size: xx-large;">Système de localisation pour une flottille de robots</center><br /><br />
			</p>

			<p>
				L'étude de nos modèles de navigation portent également sur la distribution du modèle sur plusieurs robots. Cette distribution doit permettre de répartir les besoins en ressources, et donc les ressources individuelles nécessaires pour chaque robot. Le principe implique que pendant qu'un robot guide le groupe, les autres peuvent être affectés à d'autres tâches, tout en suivant le robot-guide. Nous avons ainsi développé un système de suivi très simple mais efficace basé sur un code-barre vertical inscrit sur un tube en papier placé au sommet de chaque robot. Ce code-barre permet d'inscrire un code sur 4 bits et fourni une approximation de l'orientation (Voir figure ci-dessous).

<br/>

			</p>
		
			<figure style="text-align:center">
				<img src="/robot/robot_barcode.jpg" alt="robot with barcode" width="300" />
			</figure>
			<p style="text-align: center">
				Le robot équipé de son code-barre vertical. Les deux lignes du haut et la ligne du bas constituent des marqueurs pour reconnaitre le code-barre. Quatre lignes peuvent ensuite figurer sur le code, fournissant un code à 4 bits (ici, le code 1001=9). La ligne de hauteur variable permet une approximation de l'orientation du robot, en comparant la hauteur de la ligne observée et la hauteur du code-barre.
			</p>

			<p>
				Template du code-barre (doit être imprimé sur une page A4) : <a href="/robot/barcode.svg">barcode.svg</a>
			</p>
			<br/>
			<p>
				Exploration avec deux robots. Un robot, ici piloté à distance, cartographie l'environnement. Le second robot suit le premier, puis, à intervalles réguliers, échangent leurs positions. Chaque robot n'enregistre qu'une partie de la carte. Notre <a href="https://gaysimon.github.io/projects/navig_swarm1_en.html">modèle de navigation bio-inspiré</a> autorise cette distribution, mais aussi une exploitation d'un tel modèle distribué.



			</p>

			<p style="text-align: center">
 				<video width="300" controls >
  					<source src="/robot/multi_robots.mp4" type="video/mp4">
					Your browser does not support the video tag.
				</video> 

			</p>

<br />
			<p>
				Code source du système de détection de code-barre :<br />
				- Classe java : <br />
			</p>

		</section>

	</div>
	
	<footer>
		<p>
			Derniers ajouts par section
		</p>

		<div class="footsection">
			<p>
				&nbsp;ROBOTS :<br />
				&nbsp;&nbsp;<a href="index.php?page=john1">Johnny </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=john2">Johnny 2.0 </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=eirl">ErnestIRL </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=psik">PsikHarpax </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=ecce">EcceRobot </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=epuck">ePuck </a> <br />
			</p>
		</div>

		<div class="footsection">
			<p>
				&nbsp;SOFTWARES :<br />
				&nbsp;&nbsp;<a href="index.html">SMA </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=vacu">vacuumSG </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=littleai">Java LittleAI </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=mvac">Microvacuum </a> <br />
				&nbsp;&nbsp;<a href="index.php?page=esimu">ErnestIRL simulator </a> <br />
			</p>


		</div>

		<div class="footsection">
			<p>
				&nbsp;Le projet Ernest
			</p>
		</div>
	</footer>

</body>
</html>
